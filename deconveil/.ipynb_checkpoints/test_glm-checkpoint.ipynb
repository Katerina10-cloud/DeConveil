{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edcb7ec7-ff3e-4e9c-84f4-608c7e24ae55",
   "metadata": {},
   "source": [
    "# NB GLM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f2071f-cc76-4aba-b3c8-00c814a43b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import warnings\n",
    "from math import floor\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from typing import Literal\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from typing import cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dad75a7-57bb-4772-8a74-955459ad066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.linalg import solve  # type: ignore\n",
    "from scipy.optimize import minimize  # type: ignore\n",
    "from scipy.special import gammaln  # type: ignore\n",
    "from scipy.special import polygamma  # type: ignore\n",
    "from scipy.stats import norm  # type: ignore\n",
    "from sklearn.linear_model import LinearRegression  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf68961-cfd7-4dda-bef2-3d36d5fec4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 499,  564,   88, 1687, 2179,  768,  725,  911,  520, 1259,  150,\n",
       "        858, 1946,   38, 4813, 1808, 2308,  118, 1318,  380])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate count data for a single gene (vector), sample \n",
    "#counts = [511, 1783, 241, 1129, 1302, 2204, 3888, 5035, 236, 468, 1424, 482, 842, 1145, 1261, 1661, 2712, 1707, 1125, 3832]\n",
    "counts = [499, 564, 88, 1687, 2179, 768, 725, 911, 520, 1259, 150, 858, 1946, 38, 4813, 1808, 2308, 118, 1318, 380]\n",
    "counts = np.array(counts)\n",
    "counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "953d6c52-00d4-4a68-ad59-6654beac1943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  499. ,   564. ,    88. ,  1687. ,  2179. ,   768. ,   725. ,\n",
       "         911. ,   520. ,  1259. ,   300. ,  1287. ,  2919. ,    95. ,\n",
       "       12032.5,  2712. ,  5770. ,   295. ,  3295. ,   950. ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate CN-induced differential gene expression\n",
    "#cnv = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0.5, 1, 1, 0.5, 1, 0.5, 1, 0.5, 1, 0.5]\n",
    "cnv = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 3, 3, 5, 5, 3, 5, 5, 5, 5]\n",
    "cnv = np.array(cnv)\n",
    "cnv = cnv/2\n",
    "counts = counts * cnv\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3461776f-3297-4b67-bbf8-bbe497293421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6949248"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate dispersion data\n",
    "disp = 0.6949248\n",
    "alpha = disp\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ffc3347-38ae-4a04-9148-e99fdbb78788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1367718, 1.0516453, 1.0494177, 1.1070994, 1.2151661, 1.2099502,\n",
       "       1.019488 , 1.0139071, 1.0614114, 0.987824 , 0.9059977, 0.8133267,\n",
       "       1.0104569, 0.960332 , 0.9471832, 0.9393154, 1.011735 , 0.9449861,\n",
       "       0.9741997, 0.7625332])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate real calculated sf data (edgeR)\n",
    "size_factors = np.array([ 1.1367718, 1.0516453, 1.0494177, 1.1070994, 1.2151661, 1.2099502, 1.0194880, 1.0139071,\n",
    "                         1.0614114, 0.9878240, 0.9059977, 0.8133267, 1.0104569, 0.9603320, 0.9471832, 0.9393154, 1.0117350,\n",
    "                         0.9449861, 0.9741997, 0.7625332])\n",
    "size_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29a5eec8-3d2c-4844-b7af-8994e61e538a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([155074, 155150, 174266, 146516, 141210, 137488, 155473, 159953,\n",
       "       146130, 160312, 168373, 191432, 158796, 168344, 159919, 190229,\n",
       "       168158, 187884, 165586, 192635])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_size = np.array([155074, 155150, 174266, 146516, 141210, 137488, 155473, 159953, 146130, 160312, 168373, 191432, \n",
    "                     158796, 168344, 159919, 190229, 168158, 187884, 165586, 192635])\n",
    "lib_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a432622-e08d-4fb3-b3c7-aa3b3be4b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate design matrix\n",
    "#X = np.array([1, 0])\n",
    "#X = np.repeat(X, [8, 8], axis=0)\n",
    "#X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "208e8f83-e6b6-4110-8f40-3ccfd04d4506",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {'condition': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
    "X = pd.DataFrame(X, index = ['sample1', 'sample2', 'sample3', 'sample4', 'sample5', 'sample6', 'sample7', 'sample8', 'sample9', 'sample10',\n",
    "                            'sample11', 'sample12', 'sample13', 'sample14', 'sample15', 'sample16', 'sample17', 'sample18', 'sample19', 'sample20'])\n",
    "X.insert(0, \"intercept\", 1)\n",
    "X = np.array(X)\n",
    "design_matrix = X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58497fc3-85fb-439c-9331-45907570b124",
   "metadata": {},
   "source": [
    "### CN normalized model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb22471-a572-4fbd-b624-c959c888e575",
   "metadata": {},
   "source": [
    "### Test GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b864c281-3485-4997-aeee-e71a9d8a939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_nll(\n",
    "    counts: np.ndarray, mu: np.ndarray, alpha: Union[float, np.ndarray]\n",
    ") -> Union[float, np.ndarray]:\n",
    "    n = len(counts)\n",
    "    alpha_neg1 = 1 / alpha\n",
    "    logbinom = gammaln(counts + alpha_neg1) - gammaln(counts + 1) - gammaln(alpha_neg1)\n",
    "    if hasattr(alpha, \"__len__\") and len(alpha) > 1:\n",
    "        return (\n",
    "            alpha_neg1 * np.log(alpha)\n",
    "            - logbinom\n",
    "            + (counts + alpha_neg1) * np.log(mu + alpha_neg1)\n",
    "            - (counts * np.log(mu))\n",
    "        ).sum(0)\n",
    "    else:\n",
    "        return (\n",
    "            n * alpha_neg1 * np.log(alpha)\n",
    "            + (\n",
    "                -logbinom\n",
    "                + (counts + alpha_neg1) * np.log(alpha_neg1 + mu)\n",
    "                - counts * np.log(mu)\n",
    "            ).sum()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29187bed-f7a7-4656-bcbe-a77226cac4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_nb_nll(counts: np.ndarray, mu: np.ndarray, alpha: np.ndarray) -> np.ndarray:\n",
    "    n = len(counts)\n",
    "    alpha_neg1 = 1 / alpha\n",
    "    logbinom = (\n",
    "        gammaln(counts[:, None] + alpha_neg1)\n",
    "        - gammaln(counts + 1)[:, None]\n",
    "        - gammaln(alpha_neg1)\n",
    "    )\n",
    "\n",
    "    if len(mu.shape) == 1:\n",
    "        return n * alpha_neg1 * np.log(alpha) + (\n",
    "            -logbinom\n",
    "            + (counts[:, None] + alpha_neg1) * np.log(mu[:, None] + alpha_neg1)\n",
    "            - (counts * np.log(mu))[:, None]\n",
    "        ).sum(0)\n",
    "    else:\n",
    "        return n * alpha_neg1 * np.log(alpha) + (\n",
    "            -logbinom\n",
    "            + (counts[:, None] + alpha_neg1) * np.log(mu + alpha_neg1)\n",
    "            - (counts[:, None] * np.log(mu))\n",
    "        ).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dce2dc4-eb75-4088-ab5e-9429e6d74469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_fit_beta(\n",
    "    counts: np.ndarray,\n",
    "    size_factors: np.ndarray,\n",
    "    cnv: np.ndarray,\n",
    "    design_matrix: np.ndarray,\n",
    "    disp: float,\n",
    "    min_mu: float = 0.5,\n",
    "    grid_length: int = 60,\n",
    "    min_beta: float = -30,\n",
    "    max_beta: float = 30,\n",
    ") -> np.ndarray:\n",
    "    \n",
    "    x_grid = np.linspace(min_beta, max_beta, grid_length)\n",
    "    y_grid = np.linspace(min_beta, max_beta, grid_length)\n",
    "    ll_grid = np.zeros((grid_length, grid_length))\n",
    "\n",
    "    def loss(beta: np.ndarray) -> np.ndarray:\n",
    "        # closure to minimize\n",
    "        design_matrix_t = design_matrix.T\n",
    "        offset = size_factors + cnv\n",
    "        mu = np.maximum(np.log(offset[:, None]) + np.exp(design_matrix @ beta), min_mu)\n",
    "        return vec_nb_nll(counts, mu, disp) + 0.5 * (1e-6 * beta**2).sum(1)\n",
    "\n",
    "    for i, x in enumerate(x_grid):\n",
    "        ll_grid[i, :] = loss(np.array([[x, y] for y in y_grid]))\n",
    "\n",
    "    min_idxs = np.unravel_index(np.argmin(ll_grid, axis=None), ll_grid.shape)\n",
    "    delta = x_grid[1] - x_grid[0]\n",
    "\n",
    "    fine_x_grid = np.linspace(\n",
    "        x_grid[min_idxs[0]] - delta, x_grid[min_idxs[0]] + delta, grid_length\n",
    "    )\n",
    "\n",
    "    fine_y_grid = np.linspace(\n",
    "        y_grid[min_idxs[1]] - delta,\n",
    "        y_grid[min_idxs[1]] + delta,\n",
    "        grid_length,\n",
    "    )\n",
    "\n",
    "    for i, x in enumerate(fine_x_grid):\n",
    "        ll_grid[i, :] = loss(np.array([[x, y] for y in fine_y_grid]))\n",
    "\n",
    "    min_idxs = np.unravel_index(np.argmin(ll_grid, axis=None), ll_grid.shape)\n",
    "    beta = np.array([fine_x_grid[min_idxs[0]], fine_y_grid[min_idxs[1]]])\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "637a6e6d-92f3-4c04-b602-aece84c85ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def irls_glm(\n",
    "    counts: np.ndarray,\n",
    "    size_factors: np.ndarray,\n",
    "    design_matrix: np.ndarray,\n",
    "    cnv: np.ndarray,\n",
    "    disp: float,\n",
    "    min_mu: float = 0.5,\n",
    "    beta_tol: float = 1e-8,\n",
    "    min_beta: float = -30,\n",
    "    max_beta: float = 30,\n",
    "    optimizer: Literal[\"BFGS\", \"L-BFGS-B\"] = \"L-BFGS-B\",\n",
    "    maxiter: int = 250,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, bool]:\n",
    "\n",
    "    assert optimizer in [\"BFGS\", \"L-BFGS-B\"]\n",
    "    \n",
    "    X = design_matrix\n",
    "    num_vars = design_matrix.shape[1]\n",
    "    \n",
    "    # if full rank, estimate initial betas for IRLS below\n",
    "    if np.linalg.matrix_rank(X) == num_vars:\n",
    "        Q, R = np.linalg.qr(X)\n",
    "        y = np.log((counts/cnv)/size_factors + 0.1)\n",
    "        #y = np.log(counts / size_factors + 0.1)\n",
    "        beta_init = solve(R, Q.T @ y)\n",
    "        beta = beta_init\n",
    "\n",
    "    else:  # Initialise intercept with log base mean\n",
    "        beta_init = np.zeros(num_vars)\n",
    "        #beta_init[0] = np.log(counts / size_factors).mean()\n",
    "        beta_init[0] = np.log((counts / cnv) / size_factors).mean()\n",
    "        beta = beta_init\n",
    "        \n",
    "    dev = 1000.0\n",
    "    dev_ratio = 1.0\n",
    "\n",
    "    ridge_factor = np.diag(np.repeat(1e-6, num_vars))\n",
    "    mu = np.maximum(np.log(cnv) + np.log(size_factors) + (np.exp(X @ beta)), min_mu)\n",
    "    #mu = np.maximum(cnv * size_factors * np.exp(X @ beta), min_mu)\n",
    "    #mu = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "    \n",
    "    converged = True\n",
    "    i = 0\n",
    "    while dev_ratio > beta_tol:\n",
    "        W = mu / (1.0 + mu * disp)\n",
    "        z = np.log((mu / cnv)/size_factors) + (counts - mu) / mu\n",
    "        #z = np.log(mu / size_factors) + (counts - mu) / mu\n",
    "        H = (X.T * W) @ X + ridge_factor\n",
    "        beta_hat = solve(H, X.T @ (W * z), assume_a=\"pos\")\n",
    "        i += 1\n",
    "\n",
    "        if sum(np.abs(beta_hat) > max_beta) > 0 or i >= maxiter:\n",
    "            # If IRLS starts diverging, use L-BFGS-B\n",
    "            def f(beta: np.ndarray) -> float:\n",
    "                # closure to minimize\n",
    "                mu_ = np.maximum(np.log(cnv) + np.log(size_factors) + np.exp(X @ beta), min_mu)\n",
    "                #mu_ = np.maximum(cnv * size_factors * np.exp(X @ beta), min_mu)\n",
    "                #mu_ = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "                \n",
    "                return nb_nll(counts, mu_, disp) + 0.5 * (ridge_factor @ beta**2).sum()\n",
    "\n",
    "            def df(beta: np.ndarray) -> np.ndarray:\n",
    "                mu_ = np.maximum(np.log(cnv) + np.log(size_factors) + np.exp(X @ beta), min_mu)\n",
    "                #mu_ = np.maximum(cnv * size_factors * np.exp(X @ beta), min_mu)\n",
    "                #mu_ = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "                return (\n",
    "                    -X.T @ counts\n",
    "                    + ((1 / disp + counts) * mu_ / (1 / disp + mu_)) @ X\n",
    "                    + ridge_factor @ beta\n",
    "                )\n",
    "\n",
    "            res = minimize(\n",
    "                f,\n",
    "                beta_init,\n",
    "                jac=df,\n",
    "                method=optimizer,\n",
    "                bounds=(\n",
    "                    [(min_beta, max_beta)] * num_vars\n",
    "                    if optimizer == \"L-BFGS-B\"\n",
    "                    else None\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            beta = res.x\n",
    "            mu = np.maximum(np.log(cnv) + np.log(size_factors) + np.exp(X @ beta), min_mu)\n",
    "            #mu = np.maximum(cnv * size_factors * np.exp(X @ beta), min_mu)\n",
    "            #mu = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "            converged = res.success\n",
    "\n",
    "            if not res.success and num_vars <= 2:\n",
    "                beta = grid_fit_beta(\n",
    "                    counts,\n",
    "                    size_factors,\n",
    "                    cnv,\n",
    "                    X,\n",
    "                    disp,\n",
    "                )\n",
    "                mu = np.maximum(np.log(cnv) + np.log(size_factors) + np.exp(X @ beta), min_mu)\n",
    "                #mu = np.maximum(cnv * size_factors * np.exp(X @ beta), min_mu)\n",
    "                #mu = np.maximum(size_factors * np.exp(X @ beta), min_mu) \n",
    "            break\n",
    "\n",
    "        beta = beta_hat\n",
    "        mu = np.maximum(np.log(cnv) + np.log(size_factors) + np.exp(X @ beta), min_mu)\n",
    "        #mu = np.maximum(cnv * size_factors * np.exp(X @ beta), min_mu)\n",
    "        #mu = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "        # Compute deviation\n",
    "        old_dev = dev\n",
    "        # Replaced deviation with -2 * nll, as in the R code\n",
    "        dev = -2 * nb_nll(counts, mu, disp)\n",
    "        dev_ratio = np.abs(dev - old_dev) / (np.abs(dev) + 0.1)\n",
    "\n",
    "    # Compute H diagonal (useful for Cook distance outlier filtering)\n",
    "    W = mu / (1.0 + mu * disp)\n",
    "    W_sq = np.sqrt(W)\n",
    "    XtWX = (X.T * W) @ X + ridge_factor\n",
    "    H = W_sq * np.diag(X @ np.linalg.inv(XtWX) @ X.T) * W_sq\n",
    "    # Return an UNthresholded mu (as in the R code)\n",
    "    # Previous quantities are estimated with a threshold though\n",
    "    mu = np.log(cnv) + np.log(size_factors) + np.exp(X @ beta)\n",
    "    #mu = cnv * size_factors * np.exp(X @ beta)\n",
    "    #mu = size_factors * np.exp(X @ beta)\n",
    "\n",
    "    #print(\"Beta parameters:\", beta), \n",
    "    #print(\"Estimated mean:\", np.array(mu)), \n",
    "    #print(\"H:\", np.array(H)),\n",
    "    #print(\"Convergence:\", converged)\n",
    "    \n",
    "    return beta, mu, H, converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "873f0b04-4e00-42c7-a92b-2144cf5a73af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.73161842, 1.3119075 ]),\n",
       " array([ 953.18681752,  881.80797295,  879.94012317,  928.3064145 ,\n",
       "        1018.92069069, 1014.54714173,  854.84397327,  850.16437064,\n",
       "         889.99687927,  828.29360724, 2820.88913364, 2532.3512964 ,\n",
       "        3146.13038115, 2990.06289253, 2949.1231561 , 2924.62619378,\n",
       "        3150.10983761, 2942.28232691, 3033.24097591, 2374.20207349]),\n",
       " array([0.10000788, 0.09999568, 0.09999534, 0.10000384, 0.10001761,\n",
       "        0.100017  , 0.09999054, 0.09998962, 0.09999718, 0.09998516,\n",
       "        0.09999921, 0.09999341, 0.10000449, 0.1000021 , 0.10000143,\n",
       "        0.10000102, 0.10000454, 0.10000132, 0.10000278, 0.09998962]),\n",
       " True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classical GLM (sf) CN induced DGE (CN amplifications)\n",
    "irls_glm(counts, size_factors, design_matrix, disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "04ab2609-d34e-4033-929a-c5b36f7968c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.73161837, 0.54422075]),\n",
       " array([ 953.18676659,  881.80792583,  879.94007615,  928.3063649 ,\n",
       "        1018.92063625, 1014.54708752,  854.8439276 ,  850.16432521,\n",
       "         889.99683172,  828.29356298, 2618.26664635, 1762.84070964,\n",
       "        2190.10953243, 3469.11096604, 3421.61213619, 2035.91425968,\n",
       "        3654.79957268, 3413.67531465, 3519.20675598, 2754.58100541]),\n",
       " array([0.10000788, 0.09999568, 0.09999534, 0.10000384, 0.10001761,\n",
       "        0.100017  , 0.09999054, 0.09998962, 0.09999718, 0.09998516,\n",
       "        0.09999815, 0.0999715 , 0.09998741, 0.10001162, 0.10001105,\n",
       "        0.09998244, 0.10001373, 0.10001095, 0.10001221, 0.10000087]),\n",
       " True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CN normalized GLM (CN amplifications)\n",
    "irls_glm(counts, size_factors, design_matrix, cnv, disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6a1ff6cc-f2f4-4a00-b34b-743ac2610659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.73161832, -0.24897681]),\n",
       " array([ 953.18671396,  881.80787715,  879.94002757,  928.30631365,\n",
       "        1018.92058   , 1014.54703151,  854.8438804 ,  850.16427828,\n",
       "         889.99678258,  828.29351725,  592.24653637,  531.66792919,\n",
       "         660.53103575,  627.76461879,  619.1693086 ,  614.02616387,\n",
       "         661.36652386,  617.73307442,  636.8298706 ,  498.46445147]),\n",
       " array([0.10000788, 0.09999568, 0.09999534, 0.10000384, 0.10001761,\n",
       "        0.100017  , 0.09999054, 0.09998962, 0.09999718, 0.09998516,\n",
       "        0.09999629, 0.09996868, 0.10002135, 0.10001   , 0.10000683,\n",
       "        0.10000489, 0.10002163, 0.10000629, 0.10001326, 0.09995071]),\n",
       " True)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classical GLM (sf) CN induced DGE (CN deletions)\n",
    "irls_glm(counts, size_factors, design_matrix, disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a6170a14-8fed-47f4-98b5-93c871d3222b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.73161837, 0.5449547 ]),\n",
       " array([ 953.18676664,  881.80792588,  879.9400762 ,  928.30636494,\n",
       "        1018.9206363 , 1014.54708758,  854.84392764,  850.16432526,\n",
       "         889.99683176,  828.29356302,  327.52362671,  588.04500383,\n",
       "         730.57251364,  347.16580349,  684.82486616,  339.56817598,\n",
       "         731.49659534,  341.61816819,  704.35812118,  275.66034566]),\n",
       " array([0.10000788, 0.09999568, 0.09999534, 0.10000384, 0.10001761,\n",
       "        0.100017  , 0.09999054, 0.09998962, 0.09999718, 0.09998516,\n",
       "        0.09988835, 0.10008231, 0.10012999, 0.09991308, 0.10011685,\n",
       "        0.09990385, 0.10013024, 0.09990638, 0.10012267, 0.09980621]),\n",
       " True)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CN normalized GLM (CN deletions)\n",
    "irls_glm(counts, size_factors, design_matrix, cnv, disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48a9f10f-94bf-492a-bb96-ee31a2862465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.74790044, 0.73913047]),\n",
       " array([ 852.39568755,  852.31785095,  852.3157305 ,  852.3692385 ,\n",
       "         852.46237584,  852.45807426,  852.2867956 ,  852.28130634,\n",
       "         852.32709459,  852.25524433, 1785.33956641, 1784.94398044,\n",
       "        1785.16100545, 1785.62095225, 1785.60716572, 1785.08799888,\n",
       "        1785.67309515, 1785.60484341, 1785.63528951, 1785.39031924]),\n",
       " array([0.1       , 0.09999998, 0.09999998, 0.09999999, 0.10000001,\n",
       "        0.10000001, 0.09999997, 0.09999997, 0.09999998, 0.09999997,\n",
       "        0.09999999, 0.09999997, 0.09999998, 0.1       , 0.1       ,\n",
       "        0.09999998, 0.10000001, 0.1       , 0.1       , 0.09999999]),\n",
       " True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irls_glm(counts, size_factors, design_matrix, cnv, disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2279b4c5-bad3-48db-aae4-5c21c10e7e44",
   "metadata": {},
   "source": [
    "Using library size variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8bea8116-dbdb-46f2-8a40-7b2643fcd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def irls(\n",
    "    counts: np.ndarray,\n",
    "    size_factors: np.ndarray,\n",
    "    design_matrix: np.ndarray,\n",
    "    cnv: np.ndarray,\n",
    "    lib_size: np.ndarray,\n",
    "    disp: float,\n",
    "    min_mu: float = 0.5,\n",
    "    beta_tol: float = 1e-8,\n",
    "    min_beta: float = -30,\n",
    "    max_beta: float = 30,\n",
    "    optimizer: Literal[\"BFGS\", \"L-BFGS-B\"] = \"L-BFGS-B\",\n",
    "    maxiter: int = 250,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, bool]:\n",
    "\n",
    "    assert optimizer in [\"BFGS\", \"L-BFGS-B\"]\n",
    "    \n",
    "    X = design_matrix\n",
    "    num_vars = design_matrix.shape[1]\n",
    "    \n",
    "    # if full rank, estimate initial betas for IRLS below\n",
    "    if np.linalg.matrix_rank(X) == num_vars:\n",
    "        Q, R = np.linalg.qr(X)\n",
    "        lib_size = lib_size * size_factors\n",
    "        lib_size = np.log(lib_size) \n",
    "        y = np.log(counts - lib_size - cnv + 0.1)\n",
    "        #y = np.log(counts / size_factors + 0.1)\n",
    "        beta_init = solve(R, Q.T @ y)\n",
    "        beta = beta_init\n",
    "\n",
    "    else:  # Initialise intercept with log base mean\n",
    "        beta_init = np.zeros(num_vars)\n",
    "        #beta_init[0] = np.log(counts / size_factors).mean()\n",
    "        beta_init[0] = np.log(counts - lib_size - cnv).mean()\n",
    "        beta = beta_init\n",
    "        \n",
    "    dev = 1000.0\n",
    "    dev_ratio = 1.0\n",
    "\n",
    "    ridge_factor = np.diag(np.repeat(1e-6, num_vars))\n",
    "    mu = np.maximum(lib_size + cnv + np.exp(X @ beta), min_mu)\n",
    "    #mu = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "    \n",
    "    converged = True\n",
    "    i = 0\n",
    "    while dev_ratio > beta_tol:\n",
    "        W = mu / (1.0 + mu * disp)\n",
    "        z = np.log(mu - lib_size - cnv) + (counts - mu) / mu\n",
    "        #z = np.log(mu / size_factors) + (counts - mu) / mu\n",
    "        H = (X.T * W) @ X + ridge_factor\n",
    "        beta_hat = solve(H, X.T @ (W * z), assume_a=\"pos\")\n",
    "        i += 1\n",
    "\n",
    "        if sum(np.abs(beta_hat) > max_beta) > 0 or i >= maxiter:\n",
    "            # If IRLS starts diverging, use L-BFGS-B\n",
    "            def f(beta: np.ndarray) -> float:\n",
    "                # closure to minimize\n",
    "                mu_ = np.maximum(lib_size + cnv + np.exp(X @ beta), min_mu)\n",
    "                #mu_ = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "                \n",
    "                return nb_nll(counts, mu_, disp) + 0.5 * (ridge_factor @ beta**2).sum()\n",
    "\n",
    "            def df(beta: np.ndarray) -> np.ndarray:\n",
    "                mu_ = np.maximum(lib_size + cnv + np.exp(X @ beta), min_mu)\n",
    "                #mu_ = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "                return (\n",
    "                    -X.T @ counts\n",
    "                    + ((1 / disp + counts) * mu_ / (1 / disp + mu_)) @ X\n",
    "                    + ridge_factor @ beta\n",
    "                )\n",
    "\n",
    "            res = minimize(\n",
    "                f,\n",
    "                beta_init,\n",
    "                jac=df,\n",
    "                method=optimizer,\n",
    "                bounds=(\n",
    "                    [(min_beta, max_beta)] * num_vars\n",
    "                    if optimizer == \"L-BFGS-B\"\n",
    "                    else None\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            beta = res.x\n",
    "            mu = np.maximum(lib_size + cnv + np.exp(X @ beta), min_mu)\n",
    "            #mu = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "            converged = res.success\n",
    "\n",
    "            if not res.success and num_vars <= 2:\n",
    "                beta = grid_fit_beta(\n",
    "                    counts,\n",
    "                    size_factors,\n",
    "                    cnv,\n",
    "                    X,\n",
    "                    disp,\n",
    "                )\n",
    "                mu = np.maximum(lib_size + cnv + np.exp(X @ beta), min_mu)\n",
    "                #mu = np.maximum(size_factors * np.exp(X @ beta), min_mu) \n",
    "            break\n",
    "\n",
    "        beta = beta_hat\n",
    "        mu = np.maximum(lib_size + cnv + np.exp(X @ beta), min_mu)\n",
    "        #mu = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "        # Compute deviation\n",
    "        old_dev = dev\n",
    "        # Replaced deviation with -2 * nll, as in the R code\n",
    "        dev = -2 * nb_nll(counts, mu, disp)\n",
    "        dev_ratio = np.abs(dev - old_dev) / (np.abs(dev) + 0.1)\n",
    "\n",
    "    # Compute H diagonal (useful for Cook distance outlier filtering)\n",
    "    W = mu / (1.0 + mu * disp)\n",
    "    W_sq = np.sqrt(W)\n",
    "    XtWX = (X.T * W) @ X + ridge_factor\n",
    "    H = W_sq * np.diag(X @ np.linalg.inv(XtWX) @ X.T) * W_sq\n",
    "    # Return an UNthresholded mu (as in the R code)\n",
    "    # Previous quantities are estimated with a threshold though\n",
    "    mu = lib_size + cnv + np.exp(X @ beta)\n",
    "    #mu = size_factors * np.exp(X @ beta)\n",
    "\n",
    "    #print(\"Beta parameters:\", beta), \n",
    "    #print(\"Estimated mean:\", np.array(mu)), \n",
    "    #print(\"H:\", np.array(H)),\n",
    "    #print(\"Convergence:\", converged)\n",
    "    \n",
    "    return beta, mu, H, converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "124f2e77-d3a3-4df8-b2ba-9cae2edd14b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.81123249, 1.17953719]),\n",
       " array([ 920.06905607,  919.99170944,  920.10577947,  919.98583924,\n",
       "         920.04209008,  920.011077  ,  919.96273378,  919.98565247,\n",
       "         919.94105733,  919.96183234, 2965.50461773, 2965.52506473,\n",
       "        2965.55517745, 2965.56268777, 2965.49755917, 2965.66277913,\n",
       "        2965.61372518, 2965.65639418, 2965.56050622, 2965.46684246]),\n",
       " array([0.1       , 0.09999998, 0.1       , 0.09999998, 0.09999999,\n",
       "        0.09999999, 0.09999998, 0.09999998, 0.09999998, 0.09999998,\n",
       "        0.09999999, 0.09999999, 0.09999999, 0.09999999, 0.09999999,\n",
       "        0.09999999, 0.09999999, 0.09999999, 0.09999999, 0.09999999]),\n",
       " True)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irls(counts, size_factors, design_matrix, lib_size, disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e57774b3-7e59-4608-812c-58c3cb177e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/vvy722dj18x7xj41n2qbdzs80000gn/T/ipykernel_1328/3707227585.py:26: RuntimeWarning: invalid value encountered in log\n",
      "  y = np.log(counts - lib_size - cnv + 0.1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m irls(counts, size_factors, design_matrix, lib_size, cnv, disp)\n",
      "Cell \u001b[0;32mIn[139], line 28\u001b[0m, in \u001b[0;36mirls\u001b[0;34m(counts, size_factors, design_matrix, cnv, lib_size, disp, min_mu, beta_tol, min_beta, max_beta, optimizer, maxiter)\u001b[0m\n\u001b[1;32m     26\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(counts \u001b[38;5;241m-\u001b[39m lib_size \u001b[38;5;241m-\u001b[39m cnv \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m#y = np.log(counts / size_factors + 0.1)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     beta_init \u001b[38;5;241m=\u001b[39m solve(R, Q\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m y)\n\u001b[1;32m     29\u001b[0m     beta \u001b[38;5;241m=\u001b[39m beta_init\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Initialise intercept with log base mean\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/linalg/_basic.py:149\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(a, b, lower, overwrite_a, overwrite_b, check_finite, assume_a, transposed)\u001b[0m\n\u001b[1;32m    146\u001b[0m b_is_1D \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    148\u001b[0m a1 \u001b[38;5;241m=\u001b[39m atleast_2d(_asarray_validated(a, check_finite\u001b[38;5;241m=\u001b[39mcheck_finite))\n\u001b[0;32m--> 149\u001b[0m b1 \u001b[38;5;241m=\u001b[39m atleast_1d(_asarray_validated(b, check_finite\u001b[38;5;241m=\u001b[39mcheck_finite))\n\u001b[1;32m    150\u001b[0m n \u001b[38;5;241m=\u001b[39m a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    152\u001b[0m overwrite_a \u001b[38;5;241m=\u001b[39m overwrite_a \u001b[38;5;129;01mor\u001b[39;00m _datacopied(a1, a)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/_lib/_util.py:240\u001b[0m, in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasked arrays are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    239\u001b[0m toarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray_chkfinite \u001b[38;5;28;01mif\u001b[39;00m check_finite \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray\n\u001b[0;32m--> 240\u001b[0m a \u001b[38;5;241m=\u001b[39m toarray(a)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m objects_ok:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:630\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    628\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar \u001b[38;5;129;01min\u001b[39;00m typecodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllFloat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "irls(counts, size_factors, design_matrix, lib_size, cnv, disp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
