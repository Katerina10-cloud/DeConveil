{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a46d3faf-a122-4456-b947-49dda41f7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel  # type: ignore\n",
    "from joblib import delayed\n",
    "from joblib import parallel_backend\n",
    "from scipy.optimize import minimize  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5ab416-942f-49c0-acab-5eb9f80b8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydeseq2 import utils\n",
    "#from pydeseq2Adj import utils_pydeseqAdj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b019af6-6c94-46c2-971b-46042a583d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefInference(inference.Inference):\n",
    "\n",
    "    \"\"\"Default DESeq2-related inference methods, using scipy/sklearn/numpy.\n",
    "\n",
    "    This object contains the interface to the default inference routines and uses\n",
    "    joblib internally for parallelization. Inherit this class or its parent to write\n",
    "    custom inference routines.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    joblib_verbosity : int\n",
    "        The verbosity level for joblib tasks. The higher the value, the more updates\n",
    "        are reported. (default: ``0``).\n",
    "    batch_size : int\n",
    "        Number of tasks to allocate to each joblib parallel worker. (default: ``128``).\n",
    "    n_cpus : int\n",
    "        Number of cpus to use. If None, all available cpus will be used.\n",
    "        (default: ``None``).\n",
    "    backend : str\n",
    "        Joblib backend.\n",
    "    \"\"\"\n",
    "    \n",
    "    fit_rough_dispersions = staticmethod(utils.fit_rough_dispersions)  # type: ignore\n",
    "    fit_moments_dispersions = staticmethod(utils.fit_moments_dispersions)  # type: ignore\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        joblib_verbosity: int = 0,\n",
    "        batch_size: int = 128,\n",
    "        n_cpus: Optional[int] = None,\n",
    "        backend: str = \"loky\",\n",
    "    ):\n",
    "        self._joblib_verbosity = joblib_verbosity\n",
    "        self._batch_size = batch_size\n",
    "        self._n_cpus = utils.get_num_processes(n_cpus)\n",
    "        self._backend = backend\n",
    "        \n",
    "    @property\n",
    "    def n_cpus(self) -> int:  # noqa: D102\n",
    "        return self._n_cpus\n",
    "\n",
    "    @n_cpus.setter\n",
    "    def n_cpus(self, n_cpus: int) -> None:\n",
    "        self._n_cpus = utils.get_num_processes(n_cpus)\n",
    "\n",
    "    def irls( \n",
    "        self,\n",
    "        counts: np.ndarray,\n",
    "        size_factors: np.ndarray,\n",
    "        design_matrix: np.ndarray,\n",
    "        disp: np.ndarray,\n",
    "        cnv: np.ndarray,\n",
    "        min_mu: float,\n",
    "        beta_tol: float,\n",
    "        min_beta: float = -30,\n",
    "        max_beta: float = 30,\n",
    "        optimizer: Literal[\"BFGS\", \"L-BFGS-B\"] = \"L-BFGS-B\",\n",
    "        maxiter: int = 250,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        with parallel_backend(self._backend, inner_max_num_threads=1):\n",
    "            res = Parallel(\n",
    "                n_jobs=self.n_cpus,\n",
    "                verbose=self._joblib_verbosity,\n",
    "                batch_size=self._batch_size,\n",
    "            )(\n",
    "                delayed(utils_pydeseqAdj.irls_glm)(\n",
    "                    counts=counts[:, i],\n",
    "                    size_factors=size_factors,\n",
    "                    design_matrix=design_matrix,\n",
    "                    disp=disp[i],\n",
    "                    cnv=cnv[:, i]\n",
    "                    min_mu=min_mu,\n",
    "                    beta_tol=beta_tol,\n",
    "                    min_beta=min_beta,\n",
    "                    max_beta=max_beta,\n",
    "                    optimizer=optimizer,\n",
    "                    maxiter=maxiter,\n",
    "                )\n",
    "                for i in range(counts.shape[1])\n",
    "            )\n",
    "        res = zip(*res)\n",
    "        MLE_lfcs_, mu_hat_, hat_diagonals_, converged_ = (np.array(m) for m in res)\n",
    "\n",
    "        return (\n",
    "            MLE_lfcs_,\n",
    "            mu_hat_.T,\n",
    "            hat_diagonals_.T,\n",
    "            converged_,\n",
    "        )\n",
    "    def alpha_mle(  # noqa: D102\n",
    "        self,\n",
    "        counts: np.ndarray,\n",
    "        design_matrix: np.ndarray,\n",
    "        mu: np.ndarray,\n",
    "        alpha_hat: np.ndarray,\n",
    "        min_disp: float,\n",
    "        max_disp: float,\n",
    "        prior_disp_var: Optional[float] = None,\n",
    "        cr_reg: bool = True,\n",
    "        prior_reg: bool = False,\n",
    "        optimizer: Literal[\"BFGS\", \"L-BFGS-B\"] = \"L-BFGS-B\",\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        with parallel_backend(self._backend, inner_max_num_threads=1):\n",
    "            res = Parallel(\n",
    "                n_jobs=self.n_cpus,\n",
    "                verbose=self._joblib_verbosity,\n",
    "                batch_size=self._batch_size,\n",
    "            )(\n",
    "                delayed(utils.fit_alpha_mle)(\n",
    "                    counts=counts[:, i],\n",
    "                    design_matrix=design_matrix,\n",
    "                    mu=mu[:, i],\n",
    "                    alpha_hat=alpha_hat[i],\n",
    "                    min_disp=min_disp,\n",
    "                    max_disp=max_disp,\n",
    "                    prior_disp_var=prior_disp_var,\n",
    "                    cr_reg=cr_reg,\n",
    "                    prior_reg=prior_reg,\n",
    "                    optimizer=optimizer,\n",
    "                )\n",
    "                for i in range(counts.shape[1])\n",
    "            )\n",
    "        res = zip(*res)\n",
    "        dispersions_, l_bfgs_b_converged_ = (np.array(m) for m in res)\n",
    "        return dispersions_, l_bfgs_b_converged_\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
