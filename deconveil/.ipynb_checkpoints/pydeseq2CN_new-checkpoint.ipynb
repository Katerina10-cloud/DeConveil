{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a19353-990a-4eb2-978e-2bde212484ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from typing import List\n",
    "from typing import Literal\n",
    "from typing import Optional\n",
    "from typing import Union\n",
    "from typing import cast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import polygamma  # type: ignore\n",
    "from scipy.stats import f  # type: ignore\n",
    "from scipy.stats import trim_mean  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fbfda4-6fb1-4105-b657-d25949fca652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from def_inference import DefaultInference                          #import custom DefInference\n",
    "from inference import Inference                                     #import custom Inference \n",
    "from pydeseq2.preprocessing import deseq2_norm_fit\n",
    "from pydeseq2.preprocessing import deseq2_norm_transform\n",
    "from pydeseq2.utils import build_design_matrix\n",
    "from pydeseq2.utils import dispersion_trend\n",
    "from pydeseq2.utils import mean_absolute_deviation\n",
    "from pydeseq2.utils import n_or_more_replicates\n",
    "from pydeseq2.utils import nb_nll\n",
    "from pydeseq2.utils import replace_underscores\n",
    "from pydeseq2.utils import robust_method_of_moments_disp\n",
    "from pydeseq2.utils import test_valid_counts\n",
    "from pydeseq2.utils import trimmed_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94300650-e83b-410c-ab6c-c1b5dcc4d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pydeseq2CN_data:\n",
    "    \"\"\"A class to implement dispersion and log fold-change (LFC) estimation.\n",
    "    Dispersions and LFCs are estimated following the DESeq2 pipeline.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : pandas.DataFrame\n",
    "        Raw counts. One column per gene, rows are indexed by sample barcodes.\n",
    "    \n",
    "    cnv : pandas.DataFrame\n",
    "        Discrete numbres. One column per gene, rows are indexed by sample barcodes.\n",
    "    \n",
    "\n",
    "    metadata : pandas.DataFrame\n",
    "        DataFrame containing sample metadata.\n",
    "        Must be indexed by sample barcodes.\n",
    "\n",
    "    design_factors : str or list\n",
    "        Name of the columns of metadata to be used as design variables.\n",
    "        (default: ``'condition'``).\n",
    "    \n",
    "    continuous_factors : list or None\n",
    "        An optional list of continuous (as opposed to categorical) factors. Any factor\n",
    "        not in ``continuous_factors`` will be considered categorical (default: ``None``).\n",
    "\n",
    "    ref_level : list or None\n",
    "        An optional list of two strings of the form ``[\"factor\", \"test_level\"]``\n",
    "        specifying the factor of interest and the reference (control) level against which\n",
    "        we're testing, e.g. ``[\"condition\", \"A\"]``. (default: ``None``).\n",
    "\n",
    "    fit_type: str\n",
    "        Either ``\"parametric\"`` or ``\"mean\"`` for the type of fitting of dispersions to\n",
    "        the mean intensity. ``\"parametric\"``: fit a dispersion-mean relation via a\n",
    "        robust gamma-family GLM. ``\"mean\"``: use the mean of gene-wise dispersion\n",
    "        estimates. Will set the fit type for the DEA and the vst transformation. If\n",
    "        needed, it can be set separately for each method.(default: ``\"parametric\"``).\n",
    "        \n",
    "    min_mu : float\n",
    "        Threshold for mean estimates. (default: ``0.5``).\n",
    "\n",
    "    min_disp : float\n",
    "        Lower threshold for dispersion parameters. (default: ``1e-8``).\n",
    "\n",
    "    max_disp : float\n",
    "        Upper threshold for dispersion parameters.\n",
    "        Note: The threshold that is actually enforced is max(max_disp, len(counts)).\n",
    "        (default: ``10``).\n",
    "        \n",
    "    refit_cooks : bool\n",
    "        Whether to refit cooks outliers. (default: ``True``).\n",
    "    \n",
    "    min_replicates : int\n",
    "        Minimum number of replicates a condition should have\n",
    "        to allow refitting its samples. (default: ``7``).\n",
    "\n",
    "    beta_tol : float\n",
    "        Stopping criterion for IRWLS. (default: ``1e-8``).\n",
    "\n",
    "        .. math:: \\vert dev_t - dev_{t+1}\\vert / (\\vert dev \\vert + 0.1) < \\beta_{tol}.\n",
    "\n",
    "    n_cpus : int\n",
    "        Number of cpus to use.  If ``None`` and if ``inference`` is not provided, all\n",
    "        available cpus will be used by the ``DefaultInference``. If both are specified\n",
    "        (i.e., ``n_cpus`` and ``inference`` are not ``None``), it will try to override\n",
    "        the ``n_cpus`` attribute of the ``inference`` object. (default: ``None``).\n",
    "\n",
    "    inference : Inference\n",
    "        Implementation of inference routines object instance.\n",
    "        (default:\n",
    "        :class:`DefaultInference <pydeseq2.default_inference.DefaultInference>`).  \n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_processes : int\n",
    "        Number of cpus to use for multiprocessing.\n",
    "\n",
    "    non_zero_idx : ndarray\n",
    "        Indices of genes that have non-uniformly zero counts.\n",
    "\n",
    "     non_zero_genes : pandas.Index\n",
    "        Index of genes that have non-uniformly zero counts.\n",
    "\n",
    "    logmeans: numpy.ndarray\n",
    "        Gene-wise mean log counts, computed in ``preprocessing.deseq2_norm_fit()``.\n",
    "\n",
    "    filtered_genes: numpy.ndarray\n",
    "        Genes whose log means are different from -âˆž, computed in\n",
    "        preprocessing.deseq2_norm_fit().\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        counts: Optional[pd.DataFrame] = None,\n",
    "        cnv: Optional[pd.DataFrame] = None,\n",
    "        metadata: Optional[pd.DataFrame] = None,\n",
    "        design_factors: Union[str, List[str]] = \"condition\",\n",
    "        continuous_factors: Optional[List[str]] = None,\n",
    "        ref_level: Optional[List[str]] = None,\n",
    "        fit_type: Literal[\"parametric\", \"mean\"] = \"parametric\",\n",
    "        min_mu: float = 0.5,\n",
    "        min_disp: float = 1e-8,\n",
    "        max_disp: float = 10.0,\n",
    "        #refit_cooks: bool = True,\n",
    "        min_replicates: int = 7,\n",
    "        beta_tol: float = 1e-8,\n",
    "        n_cpus: Optional[int] = None,\n",
    "        inference: Optional[Inference] = None,\n",
    "        quiet: bool = False,\n",
    "    ): -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize object\n",
    "        \"\"\"\n",
    "\n",
    "        self.counts = counts\n",
    "        self.cnv = cnv\n",
    "\n",
    "        if len(self.counts) != len(self.cnv) or len(self.counts[0]) != len(self.cnv[0]):\n",
    "            raise ValueError(\"Matrices must have the same dimensions for element-wise operations.\")\n",
    "\n",
    "        # Test counts before going further\n",
    "        test_valid_counts(counts)\n",
    "\n",
    "        self.metadata = metadata\n",
    "        self.fit_type = fit_type\n",
    "\n",
    "        # Convert design_factors to list if a single string was provided.\n",
    "        self.design_factors = (\n",
    "            [design_factors] if isinstance(design_factors, str) else design_factors\n",
    "        )\n",
    "\n",
    "        self.continuous_factors = continuous_factors\n",
    "\n",
    "        # Build the design matrix\n",
    "        self.design_matrix = build_design_matrix(\n",
    "            metadata=self.metadata,\n",
    "            design_factors=self.design_factors,\n",
    "            continuous_factors=self.continuous_factors,\n",
    "            ref_level=ref_level,\n",
    "            expanded=False,\n",
    "            intercept=True,\n",
    "        )\n",
    "        \n",
    "        self.obsm={}\n",
    "        self.obsm[\"design_matrix\"] = self.design_matrix \n",
    "\n",
    "        # Check that the design matrix has full rank\n",
    "        #self._check_full_rank_design()\n",
    "        \n",
    "        self.min_mu = min_mu\n",
    "        self.min_disp = min_disp\n",
    "        self.max_disp = np.maximum(max_disp, self.n_obs)\n",
    "        self.ref_level = ref_level\n",
    "        self.min_replicates = min_replicates\n",
    "        self.beta_tol = beta_tol\n",
    "        self.quiet = quiet\n",
    "        self.logmeans = None\n",
    "        self.filtered_genes = None\n",
    "        \n",
    "        if inference:\n",
    "            if hasattr(inference, \"n_cpus\"):\n",
    "                if n_cpus:\n",
    "                    inference.n_cpus = n_cpus\n",
    "            else:\n",
    "                warnings.warn(\n",
    "                    \"The provided inference object does not have an n_cpus \"\n",
    "                    \"attribute, cannot override `n_cpus`.\",\n",
    "                    UserWarning,\n",
    "                    stacklevel=2,\n",
    "                )\n",
    "        # Initialize the inference object.\n",
    "        self.inference = inference or DefaultInference(n_cpus=n_cpus)\n",
    "        \n",
    "\n",
    "    def vst(\n",
    "        self,\n",
    "        use_design: bool = False,\n",
    "        fit_type: Optional[Literal[\"parametric\", \"mean\"]] = None,\n",
    "    ) -> None:\n",
    "        \n",
    "        \"\"\"Fit a variance stabilizing transformation, and apply it to normalized counts.\n",
    "        Results are stored in ``vst_counts\"``.\n",
    "        \"\"\"\n",
    "        \n",
    "        if fit_type is not None:\n",
    "            self.vst_fit_type = fit_type\n",
    "        else:\n",
    "            self.vst_fit_type = self.fit_type\n",
    "\n",
    "        print(f\"Fit type used for VST : {self.vst_fit_type}\")\n",
    "        self.vst_fit(use_design=use_design)\n",
    "        self.layers={}\n",
    "        self.layers[\"vst_counts\"] = self.vst_transform()\n",
    "        #self.parameters.append(result.params)\n",
    "        \n",
    "        return vst_counts\n",
    "        \n",
    "\n",
    "    def vst_fit(\n",
    "        self,\n",
    "        use_design: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"Fit a variance stabilizing transformation.\n",
    "\n",
    "        This method should be called before `vst_transform`.\n",
    "\n",
    "        Results are stored in ``dds.vst_counts``.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        use_design : bool\n",
    "            Whether to use the full design matrix to fit dispersions and the trend curve.\n",
    "            If False, only an intercept is used.\n",
    "            Only useful if ``fit_type = \"parametric\"`.\n",
    "            (default: ``False``).\n",
    "        \"\"\"\n",
    "        # Start by fitting median-of-ratio size factors if not already present,\n",
    "        # or if they were computed iteratively\n",
    "        if \"size_factors\" not in self.obsm or self.logmeans is None:\n",
    "            self.fit_size_factors()  # by default, fit_type != \"iterative\"\n",
    "\n",
    "        if not hasattr(self, \"vst_fit_type\"):\n",
    "            self.vst_fit_type = self.fit_type\n",
    "\n",
    "        if use_design:\n",
    "            if self.vst_fit_type == \"parametric\":\n",
    "                self._fit_parametric_dispersion_trend(vst=True)\n",
    "            else:\n",
    "                warnings.warn(\n",
    "                    \"use_design=True is only useful when fit_type='parametric'. \",\n",
    "                    UserWarning,\n",
    "                    stacklevel=2,\n",
    "                )\n",
    "                self.fit_genewise_dispersions(vst=True)\n",
    "\n",
    "        else:\n",
    "            # Reduce the design matrix to an intercept and reconstruct at the end\n",
    "            self.obsm[\"design_matrix_buffer\"] = self.obsm[\"design_matrix\"].copy()\n",
    "            self.obsm[\"design_matrix\"] = pd.DataFrame(\n",
    "                1, index=self.obs_names, columns=[[\"intercept\"]]\n",
    "            )\n",
    "            # Fit the trend curve with an intercept design\n",
    "            self.fit_genewise_dispersions(vst=True)\n",
    "            if self.vst_fit_type == \"parametric\":\n",
    "                self._fit_parametric_dispersion_trend(vst=True)\n",
    "\n",
    "            # Restore the design matrix and free buffer\n",
    "            self.obsm[\"design_matrix\"] = self.obsm[\"design_matrix_buffer\"].copy()\n",
    "            del self.design_matrix_buffer\n",
    "            \n",
    "        \n",
    "    def vst_transform(self, counts: Optional[np.ndarray] = None) -> np.ndarray:\n",
    "        \n",
    "        \"\"\"Apply the variance stabilizing transformation.\n",
    "        Uses the results from the ``vst_fit`` method.\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Variance stabilized counts.\n",
    "        \"\"\"\n",
    "        \n",
    "        if \"size_factors\" not in self.obsm:\n",
    "            raise RuntimeError(\n",
    "                \"The vst_fit method should be called prior to vst_transform.\"\n",
    "            )\n",
    "\n",
    "        if counts is None:\n",
    "            # the transformed counts will be the current ones\n",
    "            normed_counts = self.layers[\"normed_counts\"]\n",
    "        else:\n",
    "            if self.logmeans is None:\n",
    "                # the size factors were still computed iteratively\n",
    "                warnings.warn(\n",
    "                    \"The size factors were fitted iteratively. They will \"\n",
    "                    \"be re-computed with the counts to be transformed. In a train/test \"\n",
    "                    \"setting with a downstream task, this would result in a leak of \"\n",
    "                    \"data from test to train set.\",\n",
    "                    UserWarning,\n",
    "                    stacklevel=2,\n",
    "                )\n",
    "                logmeans, filtered_genes = deseq2_norm_fit(counts)\n",
    "            else:\n",
    "                logmeans, filtered_genes = self.logmeans, self.filtered_genes\n",
    "\n",
    "            normed_counts, _ = deseq2_norm_transform(counts, logmeans, filtered_genes)\n",
    "            \n",
    "        self.uns={}\n",
    "        if self.vst_fit_type == \"parametric\":\n",
    "            if \"vst_trend_coeffs\" not in self.uns:\n",
    "                raise RuntimeError(\"Fit the dispersion curve prior to applying VST.\")\n",
    "\n",
    "            a0, a1 = self.uns[\"vst_trend_coeffs\"]\n",
    "            return np.log2(\n",
    "                (\n",
    "                    1\n",
    "                    + a1\n",
    "                    + 2 * a0 * normed_counts\n",
    "                    + 2 * np.sqrt(a0 * normed_counts * (1 + a1 + a0 * normed_counts))\n",
    "                )\n",
    "                / (4 * a0)\n",
    "            )\n",
    "        self.varm{}\n",
    "        elif self.vst_fit_type == \"mean\":\n",
    "            gene_dispersions = self.varm[\"vst_genewise_dispersions\"]\n",
    "            use_for_mean = gene_dispersions > 10 * self.min_disp\n",
    "            mean_disp = trim_mean(gene_dispersions[use_for_mean], proportiontocut=0.001)\n",
    "            return (\n",
    "                2 * np.arcsinh(np.sqrt(mean_disp * normed_counts))\n",
    "                - np.log(mean_disp)\n",
    "                - np.log(4)\n",
    "            ) / np.log(2)\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                f\"Found fit_type '{self.vst_fit_type}'. Expected 'parametric' or 'mean'.\"\n",
    "            )\n",
    "    \n",
    "    def deseq2(self, fit_type: Optional[Literal[\"parametric\", \"mean\"]] = None) -> None:\n",
    "        \n",
    "        \"\"\"Perform dispersion and log fold-change (LFC) estimation.\n",
    "\n",
    "        Wrapper for the first part of the PyDESeq2 pipeline.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fit_type : str\n",
    "            Either None, ``\"parametric\"`` or ``\"mean\"`` for the type of fitting of\n",
    "            dispersions to the mean intensity.``\"parametric\"``: fit a dispersion-mean\n",
    "            relation via a robust gamma-family GLM. ``\"mean\"``: use the mean of\n",
    "            gene-wise dispersion estimates.\n",
    "\n",
    "            If None, the fit_type provided at class initialization is used.\n",
    "            (default: ``None``).\n",
    "        \"\"\"\n",
    "        \n",
    "        if fit_type is not None:\n",
    "            self.fit_type = fit_type\n",
    "            print(f\"Using {self.fit_type} fit type.\")\n",
    "        # Compute DESeq2 normalization factors using the Median-of-ratios method\n",
    "        self.fit_size_factors()\n",
    "        # Fit an independent negative binomial model per gene\n",
    "        self.fit_genewise_dispersions()\n",
    "        # Fit a parameterized trend curve for dispersions, of the form\n",
    "        # f(\\mu) = \\alpha_1/\\mu + a_0\n",
    "        self.fit_dispersion_trend()\n",
    "        # Compute prior dispersion variance\n",
    "        self.fit_dispersion_prior()\n",
    "        # Refit genewise dispersions a posteriori (shrinks estimates towards trend curve)\n",
    "        self.fit_MAP_dispersions()\n",
    "        # Fit log-fold changes (in natural log scale)\n",
    "        self.fit_LFC()\n",
    "\n",
    "    def fit_size_factors(\n",
    "        self,\n",
    "        fit_type: Literal[\"ratio\", \"poscounts\", \"iterative\"] = \"ratio\",\n",
    "        control_genes: Optional[\n",
    "            Union[np.ndarray, List[str], List[int], pd.Index]\n",
    "        ] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Fit sample-wise deseq2 normalization (size) factors.\n",
    "        Parameters\n",
    "        ----------\n",
    "        fit_type : str\n",
    "            The normalization method to use: \"ratio\", \"poscounts\" or \"iterative\".\n",
    "            (default: ``\"ratio\"``).\n",
    "        control_genes : ndarray, list, pandas.Index, or None\n",
    "            Genes to use as control genes for size factor fitting. If None, all genes\n",
    "            are used. (default: ``None``).\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.quiet:\n",
    "            print(\"Fitting size factors...\", file=sys.stderr)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # If control genes are provided, set a mask where those genes are True\n",
    "        if control_genes is not None:\n",
    "            _control_mask = np.zeros(self.counts.shape[1], dtype=bool)\n",
    "\n",
    "            # Use AnnData internal indexing to get gene index array\n",
    "            # Allows bool/int/var_name to be provided\n",
    "            _control_mask[self._normalize_indices((slice(None), control_genes))[1]] = (\n",
    "                True\n",
    "            )\n",
    "\n",
    "        # Otherwise mask all genes to be True\n",
    "        else:\n",
    "            _control_mask = np.ones(self.counts.shape[1], dtype=bool)\n",
    "\n",
    "        if fit_type == \"iterative\":\n",
    "            self._fit_iterate_size_factors()\n",
    "\n",
    "        elif fit_type == \"poscounts\":\n",
    "\n",
    "            # Calculate logcounts for x > 0 and take the mean for each gene\n",
    "            log_counts = np.zeros_like(self.counts, dtype=float)\n",
    "            np.log(self.counts, out=log_counts, where=self.counts != 0)\n",
    "            logmeans = log_counts.mean(0)\n",
    "\n",
    "            # Determine which genes are usable (finite logmeans)\n",
    "            self.filtered_genes = (~np.isinf(logmeans)) & (logmeans > 0)\n",
    "            _control_mask &= self.filtered_genes\n",
    "\n",
    "            # Calculate size factor per sample\n",
    "            def sizeFactor(x):\n",
    "                _mask = np.logical_and(_control_mask, x > 0)\n",
    "                return np.exp(np.median(np.log(x[_mask]) - logmeans[_mask]))\n",
    "\n",
    "            sf = np.apply_along_axis(sizeFactor, 1, self.counts)\n",
    "            del log_counts\n",
    "\n",
    "            # Normalize size factors to a geometric mean of 1 to match DESeq\n",
    "            self.obsm[\"size_factors\"] = sf / (np.exp(np.mean(np.log(sf))))\n",
    "            self.layers[\"normed_counts\"] = self.counts / self.obsm[\"size_factors\"][:, None]\n",
    "            self.logmeans = logmeans\n",
    "\n",
    "        # Test whether it is possible to use median-of-ratios.\n",
    "        elif (self.counts == 0).any(0).all():\n",
    "            # There is at least a zero for each gene\n",
    "            warnings.warn(\n",
    "                \"Every gene contains at least one zero, \"\n",
    "                \"cannot compute log geometric means. Switching to iterative mode.\",\n",
    "                UserWarning,\n",
    "                stacklevel=2,\n",
    "            )\n",
    "            self._fit_iterate_size_factors()\n",
    "\n",
    "        else:\n",
    "            self.logmeans, self.filtered_genes = deseq2_norm_fit(self.counts)\n",
    "            _control_mask &= self.filtered_genes\n",
    "\n",
    "            (\n",
    "                self.layers[\"normed_counts\"],\n",
    "                self.obsm[\"size_factors\"],\n",
    "            ) = deseq2_norm_transform(self.counts, self.logmeans, _control_mask)\n",
    "\n",
    "        end = time.time()\n",
    "        self.varm[\"_normed_means\"] = self.layers[\"normed_counts\"].mean(0)\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end - start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "            \n",
    "    \n",
    "    def fit_genewise_dispersions(self, vst=False) -> None:\n",
    "        \n",
    "        \"\"\"Fit gene-wise dispersion estimates.\n",
    "\n",
    "        Fits a negative binomial per gene, independently.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        vst : bool\n",
    "            Whether the dispersion estimates are being fitted as part of the VST\n",
    "            pipeline. (default: ``False``).\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check that size factors are available. If not, compute them.\n",
    "        if \"size_factors\" not in self.obsm:\n",
    "            self.fit_size_factors()\n",
    "            \n",
    "        # Exclude genes with all zeroes\n",
    "        self.varm[\"non_zero\"] = ~(self.counts == 0).all(axis=0)\n",
    "        self.non_zero_idx = np.arange(self.n_vars)[self.varm[\"non_zero\"]]\n",
    "        self.non_zero_genes = self.var_names[self.varm[\"non_zero\"]]\n",
    "\n",
    "        if isinstance(self.non_zero_genes, pd.MultiIndex):\n",
    "            raise ValueError(\"non_zero_genes should not be a MultiIndex\")\n",
    "\n",
    "        # Fit \"method of moments\" dispersion estimates\n",
    "        self._fit_MoM_dispersions()\n",
    "\n",
    "        # Convert design_matrix to numpy for speed\n",
    "        design_matrix = self.obsm[\"design_matrix\"].values\n",
    "       \n",
    "         # with a GLM (using rough dispersion estimates).\n",
    "        if (\n",
    "            len(self.obsm[\"design_matrix\"].value_counts())\n",
    "            == self.obsm[\"design_matrix\"].shape[-1]\n",
    "        ):\n",
    "            mu_hat_ = self.inference.lin_reg_mu(\n",
    "                counts=self.counts[:, self.non_zero_idx],\n",
    "                size_factors=self.obsm[\"size_factors\"],\n",
    "                design_matrix=design_matrix,\n",
    "                min_mu=self.min_mu,\n",
    "            )\n",
    "        else:\n",
    "            _, mu_hat_, _, _ = self.inference.irls_glm(\n",
    "                counts=self.counts[:, self.non_zero_idx],\n",
    "                size_factors=self.obsm[\"size_factors\"],\n",
    "                design_matrix=design_matrix,\n",
    "                disp=self.varm[\"_MoM_dispersions\"][self.non_zero_idx],\n",
    "                min_mu=self.min_mu,\n",
    "                beta_tol=self.beta_tol,\n",
    "            )\n",
    "        mu_param_name = \"_vst_mu_hat\" if vst else \"_mu_hat\"\n",
    "        disp_param_name = \"vst_genewise_dispersions\" if vst else \"genewise_dispersions\"\n",
    "\n",
    "        self.layers[mu_param_name] = np.full((self.n_obs, self.n_vars), np.nan)\n",
    "        self.layers[mu_param_name][:, self.varm[\"non_zero\"]] = mu_hat_\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting dispersions...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "        dispersions_, l_bfgs_b_converged_ = self.inference.alpha_mle(\n",
    "            counts=self.counts[:, self.non_zero_idx],\n",
    "            design_matrix=design_matrix,\n",
    "            mu=self.layers[mu_param_name][:, self.non_zero_idx],\n",
    "            alpha_hat=self.varm[\"_MoM_dispersions\"][self.non_zero_idx],\n",
    "            min_disp=self.min_disp,\n",
    "            max_disp=self.max_disp,\n",
    "        )\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end - start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "\n",
    "        self.varm[\"disp_param_name\"] = np.full(self.n_vars, np.nan)\n",
    "        self.varm[\"disp_param_name\"][self.varm[\"non_zero\"]] = np.clip(\n",
    "            dispersions_, self.min_disp, self.max_disp\n",
    "        )\n",
    "\n",
    "        self.varm[\"_genewise_converged\"] = np.full(self.n_vars, np.nan)\n",
    "        self.varm[\"_genewise_converged\"][self.varm[\"non_zero\"]] = l_bfgs_b_converged_\n",
    "\n",
    "\n",
    "    def fit_dispersion_trend(self, vst: bool = False) -> None:\n",
    "        \n",
    "        \"\"\"Fit the dispersion trend curve.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        vst : bool\n",
    "            Whether the dispersion trend curve is being fitted as part of the VST\n",
    "            pipeline. (default: ``False``).\n",
    "        \"\"\"\n",
    "        disp_param_name = \"vst_genewise_dispersions\" if vst else \"genewise_dispersions\"\n",
    "        fit_type = self.vst_fit_type if vst else self.fit_type\n",
    "\n",
    "         # Check that genewise dispersions are available. If not, compute them.\n",
    "        if disp_param_name not in self.varm:\n",
    "            self.fit_genewise_dispersions(vst)\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting dispersion trend curve...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "\n",
    "        if fit_type == \"parametric\":\n",
    "            self._fit_parametric_dispersion_trend(vst)\n",
    "        elif fit_type == \"mean\":\n",
    "            self._fit_mean_dispersion_trend(vst)\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                f\"Expected 'parametric' or 'mean' trend curve fit \"\n",
    "                f\"types, received {fit_type}\"\n",
    "            )\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end - start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "\n",
    "    def disp_function(self, x):\n",
    "        \"\"\"Return the dispersion trend function at x.\"\"\"\n",
    "        if self.uns[\"disp_function_type\"] == \"parametric\":\n",
    "            return dispersion_trend(x, self.uns[\"trend_coeffs\"])\n",
    "        elif self.disp_function_type == \"mean\":\n",
    "            return np.full_like(x, self.uns[\"mean_disp\"])\n",
    "            \n",
    "\n",
    "    def fit_dispersion_prior(self) -> None:\n",
    "        \"\"\"Fit dispersion variance priors and standard deviation of log-residuals.\n",
    "\n",
    "        The computation is based on genes whose dispersions are above 100 * min_disp.\n",
    "\n",
    "        Note: when the design matrix has fewer than 3 degrees of freedom, the\n",
    "        estimate of log dispersions is likely to be imprecise.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check that the dispersion trend curve was fitted. If not, fit it.\n",
    "        if \"fitted_dispersions\" not in self.varm:\n",
    "            self.fit_dispersion_trend()\n",
    "        \n",
    "        # Exclude genes with all zeroes\n",
    "        num_samples = self.n_obs\n",
    "        num_vars = self.obsm[\"design_matrix\"].shape[-1]\n",
    "\n",
    "        # Check the degrees of freedom\n",
    "        if (num_samples - num_vars) <= 3:\n",
    "            warnings.warn(\n",
    "                \"As the residual degrees of freedom is less than 3, the distribution \"\n",
    "                \"of log dispersions is especially asymmetric and likely to be poorly \"\n",
    "                \"estimated by the MAD.\",\n",
    "                UserWarning,\n",
    "                stacklevel=2,\n",
    "            )\n",
    "\n",
    "        # Fit dispersions to the curve, and compute log residuals\n",
    "        disp_residuals = np.log(\n",
    "            self[:, self.non_zero_genes].varm[\"genewise_dispersions\"]\n",
    "        ) - np.log(self[:, self.non_zero_genes].varm[\"fitted_dispersions\"])\n",
    "\n",
    "        # Compute squared log-residuals and prior variance based on genes whose\n",
    "        # dispersions are above 100 * min_disp. This is to reproduce DESeq2's behaviour.\n",
    "        above_min_disp = self[:, self.non_zero_genes].varm[\"genewise_dispersions\"] >= (\n",
    "            100 * self.min_disp\n",
    "        )\n",
    "\n",
    "        self.uns[\"_squared_logres\"] = (\n",
    "            mean_absolute_deviation(disp_residuals[above_min_disp]) ** 2\n",
    "        )\n",
    "\n",
    "        self.uns[\"prior_disp_var\"] = np.maximum(\n",
    "            self._squared_logres - polygamma(1, (num_samples - num_vars) / 2),\n",
    "            0.25,\n",
    "        )\n",
    "\n",
    "    def fit_MAP_dispersions(self) -> None:\n",
    "        \"\"\"Fit Maximum a Posteriori dispersion estimates.\n",
    "\n",
    "        After MAP dispersions are fit, filter genes for which we don't apply shrinkage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check that the dispersion prior variance is available. If not, compute it.\n",
    "        if \"prior_disp_var\" not in self.uns:\n",
    "            self.fit_dispersion_prior()\n",
    "        \n",
    "        # Convert design matrix to numpy for speed\n",
    "        design_matrix = self.obsm[\"design_matrix\"].values\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting MAP dispersions...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "        dispersions_, l_bfgs_b_converged_ = self.inference.alpha_mle(\n",
    "            counts=self.counts[:, self.non_zero_idx],\n",
    "            design_matrix=design_matrix,\n",
    "            mu=self.layers[\"_mu_hat\"][:, self.non_zero_idx],\n",
    "            alpha_hat=self.varm[\"fitted_dispersions\"][self.non_zero_idx],\n",
    "            min_disp=self.min_disp,\n",
    "            max_disp=self.max_disp,\n",
    "            prior_disp_var=self.uns[\"prior_disp_var\"].item(),\n",
    "            cr_reg=True,\n",
    "            prior_reg=True,\n",
    "        )\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end-start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "\n",
    "        self.varm[\"MAP_dispersions\"] = np.full(self.n_vars, np.nan)\n",
    "        self.varm[\"MAP_dispersions\"][self.varm[\"non_zero\"]] = np.clip(\n",
    "            dispersions_, self.min_disp, self.max_disp\n",
    "        )\n",
    "\n",
    "        self.varm[\"_MAP_converged\"] = np.full(self.n_vars, np.nan)\n",
    "        self.varm[\"_MAP_converged\"][self.varm[\"non_zero\"]] = l_bfgs_b_converged_\n",
    "\n",
    "        # Filter outlier genes for which we won't apply shrinkage\n",
    "        self.varm[\"dispersions\"] = self.varm[\"MAP_dispersions\"].copy()\n",
    "        self.varm[\"_outlier_genes\"] = np.log(self.varm[\"genewise_dispersions\"]) > np.log(\n",
    "            self.varm[\"fitted_dispersions\"]\n",
    "        ) + 2 * np.sqrt(self.uns[\"_squared_logres\"])\n",
    "        self.varm[\"dispersions\"][self.varm[\"_outlier_genes\"]] = self.varm[\"genewise_dispersions\"]\n",
    "        [self.varm[\"_outlier_genes\"]]\n",
    "        \n",
    "    \n",
    "    def fit_LFC(self) -> None:\n",
    "        \"\"\"Fit log fold change (LFC) coefficients.\n",
    "\n",
    "        In the 2-level setting, the intercept corresponds to the base mean,\n",
    "        while the second is the actual LFC coefficient, in natural log scale.\n",
    "        \"\"\"\n",
    "        \n",
    "         # Check that MAP dispersions are available. If not, compute them.\n",
    "        if \"dispersions\" not in self.varm:\n",
    "            self.fit_MAP_dispersions()\n",
    "            \n",
    "         # Convert design matrix to numpy for speed\n",
    "        design_matrix = self.obsm[\"design_matrix\"].values\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting LFCs...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "        mle_lfcs_, mu_, hat_diagonals_, converged_ = self.inference.irls(\n",
    "            counts=self.counts[:, self.non_zero_idx],\n",
    "            size_factors=self.obsm[\"size_factors\"],\n",
    "            design_matrix=design_matrix,\n",
    "            disp=self.varm[\"dispersions\"][self.non_zero_idx],\n",
    "            min_mu=self.min_mu,\n",
    "            beta_tol=self.beta_tol,\n",
    "        )\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end-start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "\n",
    "        self.varm[\"LFC\"] = pd.DataFrame(\n",
    "            np.nan,\n",
    "            index=self.var_names,\n",
    "            columns=self.obsm[\"design_matrix\"].columns,\n",
    "        )\n",
    "\n",
    "        self.varm[\"LFC\"].update(\n",
    "            pd.DataFrame(\n",
    "                mle_lfcs_,\n",
    "                index=self.non_zero_genes,\n",
    "                columns=self.obsm[\"design_matrix\"].columns,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.obsm[\"_mu_LFC\"] = mu_\n",
    "        self.obsm[\"_hat_diagonals\"] = hat_diagonals_\n",
    "\n",
    "        self.varm[\"_LFC_converged\"] = np.full(self.n_vars, np.nan)\n",
    "        self.varm[\"_LFC_converged\"][self.varm[\"non_zero\"]] = converged_\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
